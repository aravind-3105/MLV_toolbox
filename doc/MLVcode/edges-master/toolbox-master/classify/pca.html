<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of pca</title>
  <meta name="keywords" content="pca">
  <meta name="description" content="Principal components analysis (alternative to princomp).">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../../index.html">Home</a> &gt;  <a href="../../../index.html">MLVcode</a> &gt; <a href="../../index.html">edges-master</a> &gt; <a href="#">toolbox-master</a> &gt; <a href="index.html">classify</a> &gt; pca.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../../index.html"><img alt="<" border="0" src="../../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for MLVcode\edges-master\toolbox-master\classify&nbsp;<img alt=">" border="0" src="../../../../right.png"></a></td></tr></table>-->

<h1>pca
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<div class="box"><strong>Principal components analysis (alternative to princomp).</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<div class="box"><strong>function [U,mu,vars] = pca( X ) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Principal components analysis (alternative to princomp).

 A simple linear dimensionality reduction technique. Use to create an
 orthonormal basis for the points in R^d such that the coordinates of a
 vector x in this basis are of decreasing importance. Instead of using all
 d basis vectors to specify the location of x, using only the first k&lt;d
 still gives a vector xhat that is close to x.

 This function operates on arrays of arbitrary dimension, by first
 converting the arrays to vectors. If X is m+1 dimensional, say of size
 [d1 x d2 x...x dm x n], then the first m dimensions of X are combined. X
 is flattened to be 2 dimensional: [dxn], with d=prod(di). Once X is
 converted to 2 dimensions of size dxn, each column represents a single
 observation, and each row is a different variable. Note that this is the
 opposite of many matlab functions such as princomp. If X is MxNxn, then
 X(:,:,i) represents the ith observation (useful for stack of n images),
 likewise for n videos X is MxNxKxn. If X is very large, it is sampled
 before running PCA. Use this function to retrieve the basis U. Use
 pcaApply to retrieve that basis coefficients for a novel vector x. Use
 pcaVisualize(X,...) for visualization of approximated X.

 To calculate residuals:
  residuals = cumsum(vars/sum(vars)); plot(residuals,'-.')

 USAGE
  [U,mu,vars] = pca( X )

 INPUTS
  X         - [d1 x ... x dm x n], treated as n [d1 x ... x dm] elements

 OUTPUTS
  U         - [d x r], d=prod(di), each column is a principal component
  mu        - [d1 x ... x dm] mean of X
  vars      - sorted eigenvalues corresponding to eigenvectors in U

 EXAMPLE
  load pcaData;
  [U,mu,vars] = pca( I3D1(:,:,1:12) );
  [Y,Xhat,avsq] = pcaApply( I3D1(:,:,1), U, mu, 5 );
  pcaVisualize( U, mu, vars, I3D1, 13, [0:12], [], 1 );
  Xr = pcaRandVec( U, mu, vars, 1, 25, 0, 3 );

 See also princomp, <a href="pcaApply.html" class="code" title="function varargout = pcaApply( X, U, mu, k )">pcaApply</a>, <a href="pcaVisualize.html" class="code" title="function varargout=pcaVisualize( U, mu, vars, X, index, ks, fname, show )">pcaVisualize</a>, <a href="pcaRandVec.html" class="code" title="function Xr = pcaRandVec( U, mu, vars, k, n, hypershpere, show )">pcaRandVec</a>, <a href="visualizeData.html" class="code" title="function visualizeData( X, k, IDX, types, C )">visualizeData</a>

 Piotr's Computer Vision Matlab Toolbox      Version 3.24
 Copyright 2014 Piotr Dollar.  [pdollar-at-gmail.com]
 Licensed under the Simplified BSD License [see external/bsd.txt]</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../../matlabicon.gif)">
</ul>
This function is called by:
<ul style="list-style-image:url(../../../../matlabicon.gif)">
<li><a href="visualizeData.html" class="code" title="function visualizeData( X, k, IDX, types, C )">visualizeData</a>	Project high dim. data unto principal components (PCA) for visualization.</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<ul style="list-style-image:url(../../../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function [U,S,V] = robustSvd( X, trials )</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [U,mu,vars] = pca( X )</a>
0002 <span class="comment">% Principal components analysis (alternative to princomp).</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% A simple linear dimensionality reduction technique. Use to create an</span>
0005 <span class="comment">% orthonormal basis for the points in R^d such that the coordinates of a</span>
0006 <span class="comment">% vector x in this basis are of decreasing importance. Instead of using all</span>
0007 <span class="comment">% d basis vectors to specify the location of x, using only the first k&lt;d</span>
0008 <span class="comment">% still gives a vector xhat that is close to x.</span>
0009 <span class="comment">%</span>
0010 <span class="comment">% This function operates on arrays of arbitrary dimension, by first</span>
0011 <span class="comment">% converting the arrays to vectors. If X is m+1 dimensional, say of size</span>
0012 <span class="comment">% [d1 x d2 x...x dm x n], then the first m dimensions of X are combined. X</span>
0013 <span class="comment">% is flattened to be 2 dimensional: [dxn], with d=prod(di). Once X is</span>
0014 <span class="comment">% converted to 2 dimensions of size dxn, each column represents a single</span>
0015 <span class="comment">% observation, and each row is a different variable. Note that this is the</span>
0016 <span class="comment">% opposite of many matlab functions such as princomp. If X is MxNxn, then</span>
0017 <span class="comment">% X(:,:,i) represents the ith observation (useful for stack of n images),</span>
0018 <span class="comment">% likewise for n videos X is MxNxKxn. If X is very large, it is sampled</span>
0019 <span class="comment">% before running PCA. Use this function to retrieve the basis U. Use</span>
0020 <span class="comment">% pcaApply to retrieve that basis coefficients for a novel vector x. Use</span>
0021 <span class="comment">% pcaVisualize(X,...) for visualization of approximated X.</span>
0022 <span class="comment">%</span>
0023 <span class="comment">% To calculate residuals:</span>
0024 <span class="comment">%  residuals = cumsum(vars/sum(vars)); plot(residuals,'-.')</span>
0025 <span class="comment">%</span>
0026 <span class="comment">% USAGE</span>
0027 <span class="comment">%  [U,mu,vars] = pca( X )</span>
0028 <span class="comment">%</span>
0029 <span class="comment">% INPUTS</span>
0030 <span class="comment">%  X         - [d1 x ... x dm x n], treated as n [d1 x ... x dm] elements</span>
0031 <span class="comment">%</span>
0032 <span class="comment">% OUTPUTS</span>
0033 <span class="comment">%  U         - [d x r], d=prod(di), each column is a principal component</span>
0034 <span class="comment">%  mu        - [d1 x ... x dm] mean of X</span>
0035 <span class="comment">%  vars      - sorted eigenvalues corresponding to eigenvectors in U</span>
0036 <span class="comment">%</span>
0037 <span class="comment">% EXAMPLE</span>
0038 <span class="comment">%  load pcaData;</span>
0039 <span class="comment">%  [U,mu,vars] = pca( I3D1(:,:,1:12) );</span>
0040 <span class="comment">%  [Y,Xhat,avsq] = pcaApply( I3D1(:,:,1), U, mu, 5 );</span>
0041 <span class="comment">%  pcaVisualize( U, mu, vars, I3D1, 13, [0:12], [], 1 );</span>
0042 <span class="comment">%  Xr = pcaRandVec( U, mu, vars, 1, 25, 0, 3 );</span>
0043 <span class="comment">%</span>
0044 <span class="comment">% See also princomp, pcaApply, pcaVisualize, pcaRandVec, visualizeData</span>
0045 <span class="comment">%</span>
0046 <span class="comment">% Piotr's Computer Vision Matlab Toolbox      Version 3.24</span>
0047 <span class="comment">% Copyright 2014 Piotr Dollar.  [pdollar-at-gmail.com]</span>
0048 <span class="comment">% Licensed under the Simplified BSD License [see external/bsd.txt]</span>
0049 
0050 <span class="comment">% set X to be zero mean, then flatten</span>
0051 d=size(X); n=d(end); d=prod(d(1:end-1));
0052 <span class="keyword">if</span>(~isa(X,<span class="string">'double'</span>)), X=double(X); <span class="keyword">end</span>
0053 <span class="keyword">if</span>(n==1); mu=X; U=zeros(d,1); vars=0; <span class="keyword">return</span>; <span class="keyword">end</span>
0054 mu = mean( X, ndims(X) );
0055 X = bsxfun(@minus,X,mu)/sqrt(n-1);
0056 X = reshape( X, d, n );
0057 
0058 <span class="comment">% make sure X not too large or SVD slow O(min(d,n)^2.5)</span>
0059 m=2500; <span class="keyword">if</span>( min(d,n)&gt;m ), X=X(:,randperm(n,m)); n=m; <span class="keyword">end</span>
0060 
0061 <span class="comment">% get principal components using the SVD of X: X=U*S*V'</span>
0062 <span class="keyword">if</span>( 0 )
0063   [U,S]=svd(X,<span class="string">'econ'</span>); vars=diag(S).^2;
0064 <span class="keyword">elseif</span>( d&gt;n )
0065   [~,SS,V]=<a href="#_sub1" class="code" title="subfunction [U,S,V] = robustSvd( X, trials )">robustSvd</a>(X'*X); vars=diag(SS);
0066   U = X * V * diag(1./sqrt(vars));
0067 <span class="keyword">else</span>
0068   [~,SS,U]=<a href="#_sub1" class="code" title="subfunction [U,S,V] = robustSvd( X, trials )">robustSvd</a>(X*X'); vars=diag(SS);
0069 <span class="keyword">end</span>
0070 
0071 <span class="comment">% discard low variance prinicipal components</span>
0072 K=vars&gt;1e-30; vars=vars(K); U=U(:,K);
0073 
0074 <span class="keyword">end</span>
0075 
0076 <a name="_sub1" href="#_subfunctions" class="code">function [U,S,V] = robustSvd( X, trials )</a>
0077 <span class="comment">% Robust version of SVD more likely to always converge.</span>
0078 <span class="comment">% [Converge issues only seem to appear on Matlab 2013a in Windows.]</span>
0079 <span class="keyword">if</span>(nargin&lt;2), trials=100; <span class="keyword">end</span>
0080 <span class="keyword">try</span> [U,S,V] = svd(X); <span class="keyword">catch</span>
0081   <span class="keyword">if</span>(trials&lt;=0), error(<span class="string">'svd did not converge'</span>); <span class="keyword">end</span>
0082   n=numel(X); j=randi(n); X(j)=X(j)+eps;
0083   [U,S,V]=<a href="#_sub1" class="code" title="subfunction [U,S,V] = robustSvd( X, trials )">robustSvd</a>(X,trials-1);
0084 <span class="keyword">end</span>
0085 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Thu 05-May-2022 15:20:21 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>