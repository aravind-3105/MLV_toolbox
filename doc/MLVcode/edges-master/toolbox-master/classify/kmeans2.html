<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of kmeans2</title>
  <meta name="keywords" content="kmeans2">
  <meta name="description" content="Fast version of kmeans clustering.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../../index.html">Home</a> &gt;  <a href="../../../index.html">MLVcode</a> &gt; <a href="../../index.html">edges-master</a> &gt; <a href="#">toolbox-master</a> &gt; <a href="index.html">classify</a> &gt; kmeans2.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../../index.html"><img alt="<" border="0" src="../../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for MLVcode\edges-master\toolbox-master\classify&nbsp;<img alt=">" border="0" src="../../../../right.png"></a></td></tr></table>-->

<h1>kmeans2
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<div class="box"><strong>Fast version of kmeans clustering.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<div class="box"><strong>function [ IDX, C, d ] = kmeans2( X, k, varargin ) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Fast version of kmeans clustering.

 Cluster the N x p matrix X into k clusters using the kmeans algorithm. It
 returns the cluster memberships for each data point in the N x 1 vector
 IDX and the K x p matrix of cluster means in C.

 This function is in some ways less general than Matlab's kmeans.m (for
 example it only uses euclidian distance), but it has some options that
 the Matlab version does not (for example, it has a notion of outliers and
 min-cluster size).  It is also many times faster than matlab's kmeans.
 General kmeans help can be found in help for the matlab implementation of
 kmeans. Note that the although the names and conventions for this
 algorithm are taken from Matlab's implementation, there are slight
 alterations (for example, IDX==-1 is used to indicate outliers).

 IDX is a n-by-1 vector used to indicated cluster membership.  Let X be a
 set of n points.  Then the ID of X - or IDX is a column vector of length
 n, where each element is an integer indicating the cluster membership of
 the corresponding element in X.  IDX(i)=c indicates that the ith point in
 X belongs to cluster c. Cluster labels range from 1 to k, and thus
 k=max(IDX) is typically the number of clusters IDX divides X into. The
 cluster label &quot;-1&quot; is reserved for outliers. IDX(i)==-1 indicates that
 the given point does not belong to any of the discovered clusters. Note
 that matlab's version of kmeans does not have outliers.

 USAGE
  [ IDX, C, d ] = kmeans2( X, k, [varargin] )

 INPUTS
  X       - [n x p] matrix of n p-dim vectors.
  k       - maximum nuber of clusters (actual number may be smaller)
  prm     - additional params (struct or name/value pairs)
   .k         - [] alternate way of specifying k (if not given above)
   .nTrial    - [1] number random restarts
   .maxIter   - [100] max number of iterations
   .display   - [0] Whether or not to display algorithm status
   .rndSeed   - [] random seed for kmeans; useful for replicability
   .outFrac   - [0] max frac points that can be treated as outliers
   .minCl     - [1] min cluster size (smaller clusters get eliminated)
   .metric    - [] metric for pdist2
   .C0        - [] initial cluster centers for first trial

 OUTPUTS
  IDX    - [n x 1] cluster membership (see above)
  C      - [k x p] matrix of centroid locations C(j,:) = mean(X(IDX==j,:))
  d      - [1 x k] d(j) is sum of distances from X(IDX==j,:) to C(j,:)
           sum(d) is a typical measure of the quality of a clustering

 EXAMPLE

 See also <a href="demoCluster.html" class="code" title="">DEMOCLUSTER</a>

 Piotr's Computer Vision Matlab Toolbox      Version 3.24
 Copyright 2014 Piotr Dollar.  [pdollar-at-gmail.com]
 Licensed under the Simplified BSD License [see external/bsd.txt]</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../../matlabicon.gif)">
<li><a href="pdist2.html" class="code" title="function D = pdist2( X, Y, metric )">pdist2</a>	Calculates the distance between sets of vectors.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../../../matlabicon.gif)">
<li><a href="demoCluster.html" class="code" title="">demoCluster</a>	Clustering demo.</li><li><a href="rbfComputeBasis.html" class="code" title="function rbfBasis = rbfComputeBasis( X, k, cluster, scale, show )">rbfComputeBasis</a>	Get locations and sizes of radial basis functions for use in rbf network.</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<ul style="list-style-image:url(../../../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function [IDX,C,d] = kmeans2main( X, k, nOut, minCl, maxt, dsp, metric, C )</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [ IDX, C, d ] = kmeans2( X, k, varargin )</a>
0002 <span class="comment">% Fast version of kmeans clustering.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% Cluster the N x p matrix X into k clusters using the kmeans algorithm. It</span>
0005 <span class="comment">% returns the cluster memberships for each data point in the N x 1 vector</span>
0006 <span class="comment">% IDX and the K x p matrix of cluster means in C.</span>
0007 <span class="comment">%</span>
0008 <span class="comment">% This function is in some ways less general than Matlab's kmeans.m (for</span>
0009 <span class="comment">% example it only uses euclidian distance), but it has some options that</span>
0010 <span class="comment">% the Matlab version does not (for example, it has a notion of outliers and</span>
0011 <span class="comment">% min-cluster size).  It is also many times faster than matlab's kmeans.</span>
0012 <span class="comment">% General kmeans help can be found in help for the matlab implementation of</span>
0013 <span class="comment">% kmeans. Note that the although the names and conventions for this</span>
0014 <span class="comment">% algorithm are taken from Matlab's implementation, there are slight</span>
0015 <span class="comment">% alterations (for example, IDX==-1 is used to indicate outliers).</span>
0016 <span class="comment">%</span>
0017 <span class="comment">% IDX is a n-by-1 vector used to indicated cluster membership.  Let X be a</span>
0018 <span class="comment">% set of n points.  Then the ID of X - or IDX is a column vector of length</span>
0019 <span class="comment">% n, where each element is an integer indicating the cluster membership of</span>
0020 <span class="comment">% the corresponding element in X.  IDX(i)=c indicates that the ith point in</span>
0021 <span class="comment">% X belongs to cluster c. Cluster labels range from 1 to k, and thus</span>
0022 <span class="comment">% k=max(IDX) is typically the number of clusters IDX divides X into. The</span>
0023 <span class="comment">% cluster label &quot;-1&quot; is reserved for outliers. IDX(i)==-1 indicates that</span>
0024 <span class="comment">% the given point does not belong to any of the discovered clusters. Note</span>
0025 <span class="comment">% that matlab's version of kmeans does not have outliers.</span>
0026 <span class="comment">%</span>
0027 <span class="comment">% USAGE</span>
0028 <span class="comment">%  [ IDX, C, d ] = kmeans2( X, k, [varargin] )</span>
0029 <span class="comment">%</span>
0030 <span class="comment">% INPUTS</span>
0031 <span class="comment">%  X       - [n x p] matrix of n p-dim vectors.</span>
0032 <span class="comment">%  k       - maximum nuber of clusters (actual number may be smaller)</span>
0033 <span class="comment">%  prm     - additional params (struct or name/value pairs)</span>
0034 <span class="comment">%   .k         - [] alternate way of specifying k (if not given above)</span>
0035 <span class="comment">%   .nTrial    - [1] number random restarts</span>
0036 <span class="comment">%   .maxIter   - [100] max number of iterations</span>
0037 <span class="comment">%   .display   - [0] Whether or not to display algorithm status</span>
0038 <span class="comment">%   .rndSeed   - [] random seed for kmeans; useful for replicability</span>
0039 <span class="comment">%   .outFrac   - [0] max frac points that can be treated as outliers</span>
0040 <span class="comment">%   .minCl     - [1] min cluster size (smaller clusters get eliminated)</span>
0041 <span class="comment">%   .metric    - [] metric for pdist2</span>
0042 <span class="comment">%   .C0        - [] initial cluster centers for first trial</span>
0043 <span class="comment">%</span>
0044 <span class="comment">% OUTPUTS</span>
0045 <span class="comment">%  IDX    - [n x 1] cluster membership (see above)</span>
0046 <span class="comment">%  C      - [k x p] matrix of centroid locations C(j,:) = mean(X(IDX==j,:))</span>
0047 <span class="comment">%  d      - [1 x k] d(j) is sum of distances from X(IDX==j,:) to C(j,:)</span>
0048 <span class="comment">%           sum(d) is a typical measure of the quality of a clustering</span>
0049 <span class="comment">%</span>
0050 <span class="comment">% EXAMPLE</span>
0051 <span class="comment">%</span>
0052 <span class="comment">% See also DEMOCLUSTER</span>
0053 <span class="comment">%</span>
0054 <span class="comment">% Piotr's Computer Vision Matlab Toolbox      Version 3.24</span>
0055 <span class="comment">% Copyright 2014 Piotr Dollar.  [pdollar-at-gmail.com]</span>
0056 <span class="comment">% Licensed under the Simplified BSD License [see external/bsd.txt]</span>
0057 
0058 <span class="comment">% get input args</span>
0059 dfs = {<span class="string">'nTrial'</span>,1, <span class="string">'maxIter'</span>,100, <span class="string">'display'</span>,0, <span class="string">'rndSeed'</span>,[],<span class="keyword">...</span>
0060   <span class="string">'outFrac'</span>,0, <span class="string">'minCl'</span>,1, <span class="string">'metric'</span>,[], <span class="string">'C0'</span>,[],<span class="string">'k'</span>,k };
0061 [nTrial,maxt,dsp,rndSeed,outFrac,minCl,metric,C0,k] = <span class="keyword">...</span>
0062   getPrmDflt(varargin,dfs); assert(~isempty(k) &amp;&amp; k&gt;0);
0063 
0064 <span class="comment">% error checking</span>
0065 <span class="keyword">if</span>(k&lt;1); error(<span class="string">'k must be greater than 1'</span>); <span class="keyword">end</span>
0066 <span class="keyword">if</span>(~ismatrix(X) || any(size(X)==0)); error(<span class="string">'Illegal X'</span>); <span class="keyword">end</span>
0067 <span class="keyword">if</span>(outFrac&lt;0 || outFrac&gt;=1), error(<span class="string">'outFrac must be in [0,1)'</span>); <span class="keyword">end</span>
0068 nOut = floor( size(X,1)*outFrac );
0069 
0070 <span class="comment">% initialize random seed if specified</span>
0071 <span class="keyword">if</span>(~isempty(rndSeed)); rand(<span class="string">'state'</span>,rndSeed); <span class="keyword">end</span>; <span class="comment">%#ok&lt;RAND&gt;</span>
0072 
0073 <span class="comment">% run kmeans2main nTrial times</span>
0074 bd=inf; t0=clock;
0075 <span class="keyword">for</span> i=1:nTrial, t1=clock; <span class="keyword">if</span>(i&gt;1), C0=[]; <span class="keyword">end</span>
0076   <span class="keyword">if</span>(dsp), fprintf(<span class="string">'kmeans2 iter %i/%i step: '</span>,i,nTrial); <span class="keyword">end</span>
0077   [IDX,C,d]=<a href="#_sub1" class="code" title="subfunction [IDX,C,d] = kmeans2main( X, k, nOut, minCl, maxt, dsp, metric, C )">kmeans2main</a>(X,k,nOut,minCl,maxt,dsp,metric,C0);
0078   <span class="keyword">if</span>(sum(d)&lt;sum(bd)), bIDX=IDX; bC=C; bd=d; <span class="keyword">end</span>
0079   <span class="keyword">if</span>(dsp), fprintf(<span class="string">'  d=%f  t=%fs\n'</span>,sum(d),etime(clock,t1)); <span class="keyword">end</span>
0080 <span class="keyword">end</span>
0081 IDX=bIDX; C=bC; d=bd; k=max(IDX);
0082 <span class="keyword">if</span>(dsp), fprintf(<span class="string">'k=%i  d=%f  t=%fs\n'</span>,k,sum(d),etime(clock,t0)); <span class="keyword">end</span>
0083 
0084 <span class="comment">% sort IDX to have biggest clusters have lower indicies</span>
0085 cnts = zeros(1,k); <span class="keyword">for</span> i=1:k; cnts(i) = sum( IDX==i ); <span class="keyword">end</span>
0086 [~,order] = sort( -cnts ); C = C(order,:); d = d(order);
0087 IDX2=IDX; <span class="keyword">for</span> i=1:k; IDX2(IDX==order(i))=i; <span class="keyword">end</span>; IDX = IDX2;
0088 
0089 <span class="keyword">end</span>
0090 
0091 <a name="_sub1" href="#_subfunctions" class="code">function [IDX,C,d] = kmeans2main( X, k, nOut, minCl, maxt, dsp, metric, C )</a>
0092 
0093 <span class="comment">% initialize cluster centers to be k random X points</span>
0094 [N,p] = size(X); k = min(k,N); t=0;
0095 IDX = ones(N,1); oldIDX = zeros(N,1);
0096 <span class="keyword">if</span>(isempty(C)), C = X(randperm(N,k),:)+randn(k,p)/1e5; <span class="keyword">end</span>
0097 
0098 <span class="comment">% MAIN LOOP: loop until the cluster assigments do not change</span>
0099 <span class="keyword">if</span>(dsp), nDg=ceil(log10(maxt-1)); fprintf(int2str2(0,nDg)); <span class="keyword">end</span>
0100 <span class="keyword">while</span>( any(oldIDX~=IDX) &amp;&amp; t&lt;maxt )
0101   <span class="comment">% assign each point to closest cluster center</span>
0102   oldIDX=IDX; D=<a href="pdist2.html" class="code" title="function D = pdist2( X, Y, metric )">pdist2</a>(X,C,metric); [mind,IDX]=min(D,[],2);
0103   
0104   <span class="comment">% do not use most distant nOut elements in computation of centers</span>
0105   mind1=sort(mind); thr=mind1(end-nOut); IDX(mind&gt;thr)=-1;
0106   
0107   <span class="comment">% Recalculate means based on new assignment, discard small clusters</span>
0108   k0=0; C=zeros(k,p);
0109   <span class="keyword">for</span> IDx=1:k
0110     ids=find(IDX==IDx); nCl=size(ids,1);
0111     <span class="keyword">if</span>( nCl&lt;minCl ), IDX(ids)=-1; <span class="keyword">continue</span>; <span class="keyword">end</span>
0112     k0=k0+1; IDX(ids)=k0; C(k0,:)=sum(X(ids,:),1)/nCl;
0113   <span class="keyword">end</span>
0114   <span class="keyword">if</span>(k0&gt;0), k=k0; C=C(1:k,:); <span class="keyword">else</span> k=1; C=X(randint2(1,1,[1 N]),:); <span class="keyword">end</span>
0115   t=t+1; <span class="keyword">if</span>(dsp), fprintf([repmat(<span class="string">'\b'</span>,[1 nDg]) int2str2(t,nDg)]); <span class="keyword">end</span>
0116 <span class="keyword">end</span>
0117 
0118 <span class="comment">% record within-cluster sums of point-to-centroid distances</span>
0119 d=zeros(1,k); <span class="keyword">for</span> i=1:k, d(i)=sum(mind(IDX==i)); <span class="keyword">end</span>
0120 
0121 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Thu 05-May-2022 14:52:24 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>